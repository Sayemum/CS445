{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b80e9042319de9550955be58c1df54ad",
     "grade": false,
     "grade_id": "cell-55667e70eb82cc48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Group Names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c70bd955418584214525dcfe3648dfd",
     "grade": true,
     "grade_id": "cell-edea4adca6b3a189",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Sayemum Hassan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32bce7b65ce3470508e15a8150a34288",
     "grade": false,
     "grade_id": "cell-26718799b1157389",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Principal Components Analysis\n",
    "\n",
    "Principal Components Analysis (PCA) is a widely used technique for dimensionality reduction.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "* Gain an understanding of PCA and how it relates to covariance matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "742412bb6122af8f8058697b19a077a5",
     "grade": false,
     "grade_id": "cell-394a056386c8fd5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Variance and Covariance Matrices\n",
    "\n",
    "The cell below plots a small two-dimensional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[-4.40394652,  5.7203612 ],\n",
    "       [-5.4420319 ,  1.93587109],\n",
    "       [-4.56570001,  4.2530108 ],\n",
    "       [-5.07827013,  1.51210658],\n",
    "       [-5.39695317,  1.25160109],\n",
    "       [-4.28688083,  4.07841531],\n",
    "       [-3.58299231,  6.30384398],\n",
    "       [-5.60152663,  2.24470856],\n",
    "       [-4.47414671,  3.54114625],\n",
    "       [-5.00867538,  3.37502121],\n",
    "       [-3.61698704,  6.57347194],\n",
    "       [-7.14400941, -1.24682603],\n",
    "       [-8.34978399, -3.85127918],\n",
    "       [-7.35710211, -1.33622093],\n",
    "       [-2.82445297,  7.90898657],\n",
    "       [-4.65304533,  3.10063785],\n",
    "       [-3.41097162,  4.96990604],\n",
    "       [-5.91298693,  1.85557319],\n",
    "       [-6.65790912, -0.91626863],\n",
    "       [-3.67245142,  5.35009044]])\n",
    "\n",
    "\n",
    "plt.plot(X[:, 0], X[:, 1], '.')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8703570c682b8c8b768d9bbadb484d1c",
     "grade": false,
     "grade_id": "cell-3b7c41e4b2ed2d66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the cell above, then answer the following questions.\n",
    "\n",
    "### Questions:\n",
    "*   Approximately where is the mean of this data set?  In other words, what is $[\\overline{x}_0, \\overline{x}_1]^T$ (where the subscripts corrspond to features)?\n",
    "*   If $\\mathbf{S}$ is the sample covariance matrix of this data set, \n",
    "    $$\\mathbf{S} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$$\n",
    "    * Which entry in $\\mathbf{S}$ corresponds to the variance of feature 0? \n",
    "    * Which entry in $\\mathbf{S}$ corresponds to the variance of feature 1? \n",
    "    * What is the value of $a$ relative to $d$?  Larger?  Smaller? Equal?\n",
    "    * What is the sign of $b$?\n",
    "    * What is the value of $b$ relative to $c$?  Larger? Smaller? Equal?\n",
    "*   If you could only keep one of the two features in this data set, which one would you pick.  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb4ea3422903ca71bb12e74275e108dc",
     "grade": true,
     "grade_id": "cell-67a3ee3340d82843",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Around (-5, 2).\n",
    "a.\n",
    "d.\n",
    "A = x, D = y.\n",
    "B is positive.\n",
    "B = y, C = x.\n",
    "Keep feature 0 since it has less variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09d16d4443488f1c70ed3c94da2365a7",
     "grade": false,
     "grade_id": "cell-c31185bc9b0d9ad3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Centering the data\n",
    "\n",
    "The first step in the PCA algorithm is to center the data by subtracting out the mean value of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is:  [-5.07204118  2.83120787]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_mean = np.mean(X, axis=0)\n",
    "print(\"The mean is: \", X_mean)\n",
    "\n",
    "X = X - X_mean # Center the data by subtracting out the mean.\n",
    "\n",
    "plt.plot(X[:, 0], X[:, 1], '.')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a63b02a384fa4e7ddff43afab82f4599",
     "grade": false,
     "grade_id": "cell-5174cfdc2e77d68c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding the Sample Covariance Matrix\n",
    "\n",
    "The next step is to calculate the sample covariance matrix.  The sample covariance matrix can be expressed as: \n",
    "\n",
    "$$\\mathbf{S} = \\frac{1}{n-1} \\sum_1^n (X_i - \\overline{X})(X_i - \\overline{X})^T $$\n",
    "\n",
    "Where $X_i$ represents the $i$th row of $X$ and $\\overline{X}$ is the sample mean. \n",
    "\n",
    "Of course... In this case, we've already centered the data, so $\\overline{X}$ is $\\mathbf{0}$ and the formula reduces to:\n",
    "\n",
    "$$\\mathbf{S} = \\frac{1}{n-1} \\sum_1^n X_i X_i^T $$\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$$\\mathbf{S} = \\frac{1}{n-1} X^T X $$\n",
    "\n",
    "Where $X$ is the full, centered, data matrix.  Lets see if it works!\n",
    "\n",
    "Once you've executed the cell below, go back and check the answers you entered above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.T times X:\n",
      " [[2.1033442  4.26897913]\n",
      " [4.26897913 9.18908776]]\n",
      "\n",
      "Numpy's version:\n",
      " [[2.1033442  4.26897913]\n",
      " [4.26897913 9.18908776]]\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0] # grab the number of samples\n",
    "\n",
    "S = X.T @ X / (n-1)\n",
    "\n",
    "print(\"X.T times X:\\n\", S)\n",
    "\n",
    "print(\"\\nNumpy's version:\\n\", np.cov(X.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76145a679a7e503fc689d7afb7dfac9c",
     "grade": false,
     "grade_id": "cell-4e67513508b2cc80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Eigenvectors\n",
    "\n",
    "The *eigenvectors* of a matrix are special vectors that don't change direction when multiplied by that matrix. In other words, multiplying a matrix by one of its eigenvectors gives the same answer as multiplying by some scalar:\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}$$\n",
    "\n",
    "Here the scalar $\\lambda$ is the known as an *eigenvalue*.\n",
    "\n",
    "Consider the matrix $$\\mathbf{A} = \\begin{bmatrix} 1 & .5 \\\\ .5 & 1 \\end{bmatrix}$$\n",
    "\n",
    "Its eigenvectors are:\n",
    "\n",
    "$$\\mathbf{v}_1 = \\begin{bmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{bmatrix}, ~~\n",
    "\\mathbf{v}_2 = \\begin{bmatrix} -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "### Question\n",
    "\n",
    "* Calculate by hand $\\mathbf{A} \\mathbf{v}_1$ and $\\mathbf{A} \\mathbf{v}_1$.  What are $\\lambda_1$ and $\\lambda_2$?\n",
    "\n",
    "\n",
    "(Note that these two eigenvectors aren't unique.  We can rescale them, and the results will still be eigenvectors.  It is common to use eigenvectors that are scaled to unit length.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea42db2bb29139cdf198ab06704cb27e",
     "grade": true,
     "grade_id": "cell-23ce7a07aad92e82",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9eaec2cef666ac58327e6caeb66a497b",
     "grade": false,
     "grade_id": "cell-46ab7c96e6f33b90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Principal Components\n",
    "\n",
    "It turns out that we can find the directions of maximum variance in a dataset by finding the eigenvectors of the covariance matrix.  The eigenvector with the largest eigenvalue points in the direction of maximum variance. **Before** executing the next cell, take a look back at the dataset above to predict the direction of the first principal component. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numpy is able to calculate eigenvalues and eigenvectors.\n",
    "#   `lambdas` contains the eigenvalues (in sorted order)\n",
    "#    The columms of `W` contain the corresponding eigenvectors.\n",
    "lambdas, W = np.linalg.eigh(S)\n",
    "\n",
    "# Lets reverse the order to get the largest first...\n",
    "\n",
    "lambdas = lambdas[::-1]\n",
    "W = W[:, ::-1]\n",
    "\n",
    "print(\"Eigenvalues:\", lambdas)\n",
    "print(\"Eigenvectors:\\n\", W)\n",
    "\n",
    "# Replot the data points\n",
    "plt.plot(X[:, 0], X[:, 1], '.')\n",
    "plt.axis('equal')\n",
    "\n",
    "# Show the first principal component.\n",
    "plt.arrow(0, 0, W[0,0] * 3, W[1,0] * 3, head_width=0.5, head_length=0.5)\n",
    "plt.title('First Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# Show the second principal component.\n",
    "plt.figure()\n",
    "plt.plot(X[:, 0], X[:, 1], '.')\n",
    "plt.axis('equal')\n",
    "plt.arrow(0, 0, W[0,1] * 3, W[1,1] * 3, head_width=0.5, head_length=0.5)\n",
    "plt.title('Second Principal Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7cde388c1d45d3444f80543ed79bc7a",
     "grade": false,
     "grade_id": "cell-92e927f814d91224",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Percentage Variance\n",
    "\n",
    "The magnitude of the eigenvectors are exactly equal to the amount of variance along the corresponding eigenvector.  If we normalize the eigenvalues, they give us the fraction of the total variance explained by each principal component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lambdas / np.sum(lambdas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61e3dd1318d975e497a6ffc71e86c926",
     "grade": false,
     "grade_id": "cell-c8c462e450454ca1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this case, around 99% of the variance is captured by the first principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afbe05c78901c5713bd83073b80b38f2",
     "grade": false,
     "grade_id": "cell-0c31c3343e2e64f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Projecting Data Onto Principal Components\n",
    "\n",
    "Once we have our principal components, we would like to know were each data point \"lands\" on each component.  In other words, we would like to project our data onto the principal components:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/300px-Dot_Product.svg.png\">\n",
    "\n",
    "Here **A** corresponds to a data point and **B** corresponds to a principal component.  In the case where **B** is a unit vector, $|\\mathbf{A}| \\cos(\\theta) = \\mathbf{A} \\cdot \\mathbf{B}$.  In other words, the projection of **A** onto **B** is just the dot product between the two.  Using this information, we can project any one of our data points onto our first principal component. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the original data and the first PC\n",
    "plt.axis('equal')\n",
    "plt.plot(X[:, 0], X[:, 1], '.', alpha=.2)\n",
    "plt.arrow(0, 0, W[0,0]*5, W[1,0]*5, head_width=0.5, head_length=0.5)\n",
    "\n",
    "# Pull out a single point and project it onto the first PC:\n",
    "x0 = X[0,:]\n",
    "x0_projected = x0 @ W[:, 0]\n",
    "print(\"Projection: \", x0_projected)\n",
    "\n",
    "# Plot the original point\n",
    "plt.plot(x0[0], x0[1], 'og', label='Original Point')\n",
    "\n",
    "# Plot where the original point is projected onto the PC:\n",
    "plt.plot(W[0,0] * x0_projected, W[1,0] * x0_projected, 'or', label='Projected Point')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(x0_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56de5708768d17582af6ab9e01a0fe07",
     "grade": false,
     "grade_id": "cell-c58f3c3a82db1a28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Projecting ALL the data\n",
    "\n",
    "We can get a rotated version of our original, centered, dataset by projecting every data point onto our two principal components.  This can be accomplished at one go by multiplying our data matrix by our matrix of principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X @ W\n",
    "# Replot the data points\n",
    "plt.plot(X_new[:, 0], X_new[:, 1], '.')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bde5acc66f09b9a94fb6d540c34a2747",
     "grade": false,
     "grade_id": "cell-32dbea847baa79ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this figure, the x-axis shows the projection of the data onto the first principal component, and the y-axis shows the projection of the data onto the second principal component.\n",
    "\n",
    "### Questions:\n",
    "You should be able to predict all of the values in the covariance matrix of this rotated version of the data without doing any additional calculations.  What are they?  If you aren't sure, take a guess and write some Python code to check your answer.\n",
    "\n",
    "$$\\mathbf{S} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$$\n",
    " * $a$: \n",
    " * $b$: \n",
    " * $c$: \n",
    " * $d$: \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee250638cb9db5edc4af13dee507ec17",
     "grade": true,
     "grade_id": "cell-6df19c646f74fd11",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70adb54aee2f1e61c09899836233ada0",
     "grade": false,
     "grade_id": "cell-43dc495dadd28b08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reducing Dimensionality\n",
    "\n",
    "In the example above, we multiplied our data matrix by a matrix containing *all* of the principal components.  We can reduce the dimensionality of the data by leaving out the principal components with smaller eigenvalues:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X @ W[:, 0] # Only the first column!\n",
    "\n",
    "# Replot the data points\n",
    "plt.plot(Z, np.zeros(Z.shape), '.')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec11a37fee67c5d0adb2440fb8d86dc2",
     "grade": false,
     "grade_id": "cell-fd44101644e9467d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Moving Back to the Original Space\n",
    "\n",
    "One way of viewing PCA is as a lossy compression algorithm: we compress the data by removing dimensions that don't carry much information.  We can then decompress by projecting our data back into the original space.  This can be done by multiplying our compressed data by the traspose of the vector of principal components that were used for compression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = np.outer(Z, W[:, 0].T) # need to use `outer `because stupid numpy \n",
    "                               # treats 1d arrays differently from column vectors\n",
    "X_hat += X_mean # restore the mean\n",
    "\n",
    "plt.plot(X_hat[:,0], X_hat[:,1], '.')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Is All of This Useful?\n",
    "\n",
    "In the example above, 99% of the variance is explained by the first principal component.  Now that the data is aligned with the principal components, we can discard the second feature, and in a sense, we are only losing 1% of the information from our original dataset. Discarding dimensions in this way can be helpful for a couple of different reasons:\n",
    "\n",
    "### Visualization\n",
    "\n",
    "Data that has four or more dimensions is essentially impossible to visualize using traditional techiques.  Using PCA we can reduce our high-dimensional data down to two or three dimensions for the purposes of visualization.  Depending on how much variance is explained by those first few dimensions, we may lose very little meaningful structure when moving to the low-dimensional space. \n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "Some machine learning algorithms will operate more efficiently, or give better results, when the dimensionality of the input data is low. PCA is a common pre-processing step for discarding \"useless\" dimensions before applying these algorithms.\n",
    "\n",
    "## A Note on Implementation\n",
    "\n",
    "In practice, we would *not* find the principal components by explicitly calculating the sample covariance matrix. Instead we would use *Singular Value Decomposition*.  Google it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The the [next notebook](pca2.ipynb) we'll look at a larger scale example of PCA and discuss some limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
